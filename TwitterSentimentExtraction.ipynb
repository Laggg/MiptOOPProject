{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./giphy.gif\" width=\"500\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sentiment Extraction** (рус. выделение эмоциональной окраски) - группа задач из области обработки естественных языков, в которых по данному тексту необходимо предсказать эмоциональную окраску и/или выделить слова, содержащие ее. <br>\n",
    "В нашем случае, исследованы обе задачи: как выделение фраз, задающих эмоциональную окраску, по эмоциональной окраске текста, так и предсказание самой эмоциональной окраски."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Используемые данные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашей работе использовался датасет от компании Twitter, предоставленный на платформе для соревнований по машинному обучению Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Для оценки качества моделей будут использоваться следущие метрики:**\n",
    "* f1-score - для оценки качества классификации текста;\n",
    "* jaccard score - для оценки качества выделения фраз, обеспечивающих эмоциональную окраску."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подробнее остановимся на метрике Jaccard score как более редко встречающейся.\n",
    "Эта метрика используется как мера сходства между двумя множествами и вычисляется по формуле:\n",
    "![jac_2.png](jac_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Т.е. мы представляем предложения как множества слов и смотрим, насколько эти множества похожи. Мы не будем писать свою реализацию этой метрики, а будем использовать готовую из nltk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Формализация задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача определения эмоциональной окраски текста формализуется более просто: по данной последовательности токенов (не обязательно слов, так как некоторые модели трансформеров используют char-based токенизацию, а некоторые - токенизацию N - грамм) предсказать один из трех возможных классов эмоциональной окраски: \"нейтральная\", \"позитивная\" и \"негативная\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для задачи выделения слов, определяющих эмоциональную окраску, есть несколько возможных формализаций.\n",
    "Мы будем использовать две:\n",
    "1. Named Entity Recognition - выделение именованных сущностей; В нашей задаче мы, по сути, будем предсказывать для предложений бинарные маски, в которых единицы стоят на местах слов, которые важны для понимания эмоциональной окраски текста, и нули - на всех остальных;\n",
    "2. Question Answering - задача поиска ответа в заданном тексте по заданному вопросу. Как мы увидим позже, эта формализация более продуктивна; причина кроется в том, что используемые модели выделяют непрерывную последовательность в токенов, что совпадает с исходной разметкой датасета, в отличие от NER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Из оспользованных моделей лучше всего показали себя две::**\n",
    "* roBERTa (классификация)\n",
    "* DistilBERT (QA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все использованные модели относятся к классу так называмых **трансформеров**. Впервые этот концепт был представлен в [2], и с тех модели, следующие некоторому общему концепту модели, достигают SOTA-результатов в NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Общая идея трансформеров не нова и взята из области Computer Vision. Она заключается в предобучении модели на каком-то большом датасете, в ходе которого модель \"понимает\" область, с которой ей предстоит работать, и следующее за ним обучение на какую-то конкретную задачу, как правило, на меньшем датасете. Однако в NLP модели для использования концепта Transfer Learning, в отличие от CV, предобучается на неразмеченном тексте, обучаясь как т.н. языковая модель - т. е. учатся предсказывать слова по левому, правому или двухстороннему контексту. \n",
    "Расскажем подробнее об архитектуре BERT-based моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bert_1.png](bert_1.png)\n",
    "![bert_2.png](bert_2.png)\n",
    "![bert_3.png](bert_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходный датасет был разделен на две части; 80% были взяты для обучения модели, на оставшихся 20% было проведено тестированное, отраженное здесь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате обучения моделей, описанных выше, были получены следующие результаты: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Классификация:\n",
    "    * roBERTa: <br>\n",
    "        * F1 - score: 0.824\n",
    "2. QA: \n",
    "    * DistilBERT: <br>\n",
    "        * Jaccard score: 0.825\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ссылки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] [DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter, oct.2019](https://arxiv.org/abs/1910.01108) <br> <br>\n",
    "[2] [Attention is all you need, 2017](https://arxiv.org/abs/1706.03762) <br> <br>\n",
    "[3] [roBERTa description from Google AI](https://ai.facebook.com/blog/roberta-an-optimized-method-for-pretraining-self-supervised-nlp-systems/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
